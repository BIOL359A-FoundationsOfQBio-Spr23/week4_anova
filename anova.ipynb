{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Data as matrices, ANOVA\n",
    "### Spring 2022, Week 3\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Understand the structure of data\n",
    "-  Gain intuition about ANOVA\n",
    "-  Read some more basic python syntax\n",
    "\n",
    "Updates from last classwork:\n",
    "-  Now that you have had time to familiarize yourselves with the interface, we will be grading some components on accuracy rather than engagement! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2 Quiz Review\n",
    "\n",
    "Question 1: \n",
    "Example of an associated variable that is neither causal nor correlated: Time and tides. Often modeled with sin curves! \n",
    "\n",
    "Question 7:\n",
    "\n",
    "- The P-value is the false positive rate of a statistical test.\n",
    "  - fix: The __alpha error__ is the false positive rate of a statistical test.\n",
    "- _The P-value is also known as the significance level of a test._\n",
    "  - fix: The __alpha__ is also known as the significance level of a test. \n",
    "- The P-value must be less than 5% to reject a hypothesis. \n",
    "  - fix: The P-value must less than the __alpha__/__significance level__ to reject a (null) hypothesis.\n",
    "- __The P-value is the probability of observing the sample or a more extreme value.__\n",
    "\n",
    "\n",
    "Question 8:\n",
    "- __The beta error depends on the properties of the alternative distribution.__\n",
    "- __The alpha error determines the threshold beyond which samples motivate rejection of the null hypothesis.__\n",
    "- _The power of a statistic depends on both the alpha and the beta error._\n",
    "  - __This statement could be argued as true or false__, so we have given everyone credit for this answer. \n",
    "- _The alpha error is anchored to observed samples._\n",
    "  - The alpha error is defined __before__ observing samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwork:\n",
    "\n",
    "reminder: Make sure you run __every__ cell using `shift`+`enter` or pressing the play button the left side of every cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr22/week3_anova\n",
    "!mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (12,12)\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1) #Change from 1 to 1.5 or 2 if you have a hard time reading text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Sample size and Power\n",
    "\n",
    "There are a number of factors that go into statistical test design. \n",
    "Sample sizes and alpha are very important to the power (our ability to reject the null hypothesis) of significance tests. \n",
    "Remember, Power is bounded between it it $1 - P(\\text{False Negative})$, or $1-\\beta$. \n",
    "The other component of power is the actual effect size (ratio of the difference in means divided by the standard deviation) that we want to be able __consistently__ label as significant. \n",
    "As quantitative biologists, we must be aware of how all of these components effect one another. \n",
    "Consider the following experiment, and answer the questions in the quiz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(effect_size = 0.1, n=1000):\n",
    "    mu_A = 0\n",
    "    sigma = 2\n",
    "    \n",
    "    mu_B = sigma*effect_size+mu_A\n",
    "    A = [random.gauss(mu_A, sigma) for _ in range(n)]\n",
    "    B = [random.gauss(mu_B, sigma) for _ in range(n)]\n",
    "    return A, B\n",
    "\n",
    "@widgets.interact_manual(effect_size=(0.0,1.0), n=[3,10,30,100])\n",
    "def run_ttest(effect_size, n):\n",
    "    A,B = run_experiment(effect_size)\n",
    "    pvalues=[]\n",
    "    for i in range(0,200):\n",
    "        tstat, pvalue = ttest(np.random.choice(A, size=n), np.random.choice(B, size=n))\n",
    "        pvalues.append(pvalue)\n",
    "    p_arr = np.array(pvalues)\n",
    "    power = 1 - np.count_nonzero((p_arr > 0.05))/p_arr.size\n",
    "    print(f\"Power: {power}\")\n",
    "    sns.histplot(pvalues, stat=\"probability\", kde=\"true\")\n",
    "    plt.title(f\"Histogram of p-values, sample size = {n}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Multiple tests\n",
    "\n",
    "Data source: https://reneshbedre.github.io/assets/posts/anova/twowayanova.txt\n",
    "\n",
    "This data is not real data, so we will not be focusing on interpreting the biological results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df = pd.read_csv(\"https://reneshbedre.github.io/assets/posts/anova/twowayanova.txt\", sep=\"\\t\")\n",
    "basic_df.columns = [\"Genotype\", \"Year1\", \"Year2\", \"Year3\"]\n",
    "subsample_genotypes = [\"A\",\"B\",\"C\",\"D\"]\n",
    "subsample = pd.concat([x for g,x in basic_df.groupby(\"Genotype\") if g in [\"A\",\"B\",\"C\",\"D\"]])\n",
    "subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorial _t_-test\n",
    "\n",
    "We have a higher chance of seeing a false positive when we run multiple tests! \n",
    "If you ran the test for 0.0 effect size, the p-value is uniformly distributed between 0 and 1, which is expected.\n",
    "That means with an alpha of 0.05, we would say 5% of our tests are significant even though we have no effect!\n",
    "Remember, alpha is our False Negative rate as well. \n",
    "The most common (and most strict) correction that we can do is divide our original $\\alpha$ by the number of tests that we run, which is called the Bonferroni correction. \n",
    "Remember that decreasing our $\\alpha$, increases our $\\beta$, abd therefore decreases our power. \n",
    "We shall explore that more in the experiment below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(year=\"Year1\"):\n",
    "    pvalues = np.zeros(shape=(4,4))\n",
    "    i=0\n",
    "    for genotype, genotype_df in subsample.groupby(\"Genotype\"):\n",
    "        for j, other_geno in enumerate(subsample_genotypes):\n",
    "            other = subsample[subsample[\"Genotype\"] == other_geno]\n",
    "            tstat, pvalue = ttest(genotype_df[year], other[year])\n",
    "            pvalues[i][j] = pvalue\n",
    "        i += 1\n",
    "        \n",
    "    mask = np.triu(np.ones_like(pvalues, dtype=bool))\n",
    "    sns.heatmap(pvalues, mask=mask, cmap=\"Blues_r\", annot=True, fmt=\"0.4f\", \n",
    "                xticklabels=subsample_genotypes,\n",
    "                yticklabels=subsample_genotypes)\n",
    "    plt.title(f\"p-values for {year}\")\n",
    "    plt.show()\n",
    "    return pvalues\n",
    "\n",
    "array_list = []\n",
    "for year in [\"Year1\", \"Year2\", \"Year3\"]:\n",
    "    array_list.append(combinations(year))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: ANOVA\n",
    "\n",
    "ANOVA, discussed on Monday, is one way that we can compare all the means between groups, so that we can reduce it to one test instead of every combination of _t_-test! \n",
    "You will see that the dataset was actually shorted for the purposes of the last exercise, but there are in fact 6 groups rather than 4 (which greatly increases the number of tests).\n",
    "\n",
    "Let's dive into ANOVA, but first we will view the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_oneway_anova(df, independent = \"Genotype\", dependent = \"Year1\"):\n",
    "    model = ols(f'{dependent} ~ C({independent})', data=df).fit()\n",
    "    aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "    sns.boxplot(data=df, y=dependent, x=independent)\n",
    "    return aov_table\n",
    "    \n",
    "@widgets.interact(dependent=[\"Year1\", \"Year2\", \"Year3\"])\n",
    "def anova_by_year(dependent):\n",
    "    return perform_oneway_anova(basic_df, independent=\"Genotype\", dependent = dependent)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_twoway_anova(df, interaction=False, ind = [\"Genotype\", \"years\"], dep = \"value\"):\n",
    "    d_melt = pd.melt(df, id_vars=['Genotype'], value_vars=['Year1', 'Year2', 'Year3'])\n",
    "    d_melt.columns = ['Genotype', 'years', 'value']\n",
    "    \n",
    "    if interaction: \n",
    "        model = ols(f'{dep} ~ C({ind[0]}) + C({ind[1]}) + C({ind[0]}):C({ind[1]})', data=d_melt).fit()\n",
    "    else: \n",
    "        model = ols(f'{dep} ~ C({ind[0]}) + C({ind[1]})', data=d_melt).fit()\n",
    "    aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "    return aov_table\n",
    "\n",
    "@widgets.interact(interaction=[False,True])\n",
    "def ineractions_twoway_anova(interaction):\n",
    "    return perform_twoway_anova(basic_df, interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: How do we represent data\n",
    "\n",
    "Why does the __structure__ of data matter? \n",
    "There is a lot of math that is important to calculating statistics. \n",
    "There is not a lot we can do with words, so we need to represent them as numbers. \n",
    "\n",
    "There are several different types of variables that contain valuable information: \n",
    "-  Categorical: Variables than can be placed into bins (something like species, or diseases)\n",
    "-  Ordinal: Ordered categorical variables (think stages of a disease)\n",
    "-  Binary (boolean): True/False (Any categorical variable can be written as multiple binary variables)\n",
    "-  Continuous: All real numbers (can be bounded)\n",
    "-  Discrete: Limited selection of distinct numbers \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We skipped a step that was important to the two-way ANOVA. We formatted our data to be as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_melt = pd.melt(basic_df, id_vars=['Genotype'], value_vars=['Year1', 'Year2', 'Year3'])\n",
    "d_melt.columns = ['Genotype', 'years', 'value']\n",
    "d_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also commonly represent data as a matrix, which is useful for a lot of mathematical operations that we may want to do, which we will discuss more in the future. \n",
    "Whenever we show you tables, we can generally refer to that as a matrix.\n",
    "However, as we just showed, rows and columns aren't intrinsic components of data. \n",
    "\n",
    "We (and the internet) will generally refer to dependent variables as __responses__ (continuous) or __labels__ (categorical), independent variables as __features__, and individual samples as __observations__. \n",
    "These are generally used as terms to describe models, but can be useful when discussing the structure of data as well.\n",
    "\n",
    "![annotated_data](annotated_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a couple of definitions out of the way, let us look at the structure of some blood test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_lab_data(n=20):\n",
    "    lab_data = pd.read_csv(\"data/hcvdat0.csv\", index_col=0)\n",
    "    lab_data = lab_data[lab_data[\"Category\"] != \"0s=suspect Blood Donor\"]\n",
    "    lab_data = lab_data.dropna(axis=0)\n",
    "    df_list = []\n",
    "    for category, category_df in lab_data.groupby(\"Category\"):\n",
    "        df_list.append(category_df.sample(12, random_state=5))\n",
    "    \n",
    "    return pd.concat(df_list)\n",
    "        \n",
    "\n",
    "lab_data = clean_lab_data()\n",
    "print(lab_data.shape)\n",
    "lab_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- albumin (ALB)\n",
    "\n",
    "- alkaline phosphatase (ALP)\n",
    "\n",
    "- alanine amino-transferase (ALT)\n",
    "\n",
    "- aspartate amino-transferase (AST)\n",
    "\n",
    "- bilirubin (BIL) \n",
    "\n",
    "- choline esterase (CHE)\n",
    "\n",
    "- cholesterol (CHOL)\n",
    "\n",
    "- creatinine (CREA)* \n",
    "\n",
    "- Î³-glutamyl-transferase (GGT)\n",
    "\n",
    "- total protein (PROT)*\n",
    "\n",
    "\\* I think, the dataset was not very well annotated.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/HCV+data#\n",
    "\n",
    "We have gone through and cleaned out some of the data that was incomplete, and also reduced the samples to be the same across all groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: ANOVA assumptions\n",
    "\n",
    "We have mentioned the idea of a \"normality\" assumption multiple times through this class, and there are statistical tests that help test for normality. \n",
    "However, those tests are a little more complicated, but one option is using QQ-plots or Quantile-Quantile plots to assess how well the data matches with a distribution. \n",
    "It is a plot comparing the probability of the sample occruing in the data, and the probability that the sample occurs in a normal distribution.\n",
    "If it falls on the line, it is safe to treat it as normal. \n",
    "\n",
    "![qqplots](qqplot.png)\n",
    "\n",
    "__Aside__: As a result of the CLT, ANOVA, similarly to t-tests, is generally robust to departures from normality and differences in variance, but at large sample sizes. If you have a small sample size, the ANOVA is no longer robust to departures from the assumptions made when designing the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@widgets.interact(feature = [\"ALB\", \"ALP\", \"ALT\", \"AST\", \"BIL\", \"CHE\", \"CHOL\", \"CREA\", \"GGT\", \"PROT\"])\n",
    "def show_hist_gg_plots(feature = \"ALB\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,8))\n",
    "    sns.histplot(data=lab_data, x=feature, hue=\"Category\", stat=\"probability\", kde=True, ax=ax1)\n",
    "    qqplot(lab_data[feature].dropna(), norm, fit=True, line=\"45\", ax=ax2)\n",
    "    plt.show()\n",
    "    return perform_oneway_anova(lab_data, independent = \"Category\", dependent = feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Looking forward to linear models\n",
    "\n",
    "There is another common way of thinking about ANOVA: a linear model where the means ($\\bar{X}_i = \\hat{\\beta}_i$ of a group are the best prediction of any individual group value.\n",
    "Remember that any categorical variable can be written as a series of binary variables. \n",
    "This transformation is called \"One-hot encoding\". \n",
    "Let's say that we have 3 groups, we can rewrite this as 3 binary features: $x_a$, $x_b$, $x_c$ that indicate what group a observation belongs to. \n",
    "If we rewrite categorical variables in this way, we can use a mathematical formula to capture the behavior of the groups to predict some response $y$:\n",
    "\n",
    "$$ y = \\hat{\\beta}_a x_a + \\hat{\\beta}_b x_b + \\hat{\\beta}_c x_c $$\n",
    "\n",
    "This result is the solution to the __least squares__ problem, which is also how we will solve the linear regression problem.\n",
    "This model (using __error__ or the __residuals__) is then compared to comparing to simply using the average of all the groups to predict $y$. \n",
    "This notation will start to look much more familiar starting next week. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
