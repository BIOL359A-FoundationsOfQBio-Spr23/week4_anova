{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Data as matrices, ANOVA\n",
    "### Spring 2023, Week 4\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Understand the structure of data\n",
    "-  Gain intuition about ANOVA\n",
    "-  Read some more basic python syntax\n",
    "\n",
    "Updates from last classwork:\n",
    "-  Now that you have had time to familiarize yourselves with the interface, we will be grading some components on __both__ accuracy and engagement! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read an ANOVA table\n",
    "\n",
    "![anova](anovatable.png)\n",
    "\n",
    "- `sum_sq`: Sum of Squares\n",
    "- `df`: Degrees of freedom (n-1)\n",
    "- `F`: F-statistic\n",
    "- `PR(>F)`: p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwork:\n",
    "\n",
    "reminder: Make sure you run __every__ cell using `shift`+`enter` or pressing the play button the left side of every cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr23/week4_anova\n",
    "!mkdir ./data\n",
    "!cp week4_anova/data/* ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (12,12)\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1) #Change from 1 to 1.5 or 2 if you have a hard time reading text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 1: Sample size and Power\n",
    "\n",
    "There are a number of factors that go into statistical test design. \n",
    "Sample sizes and alpha are very important to the power (our ability to reject the null hypothesis) of significance tests. \n",
    "Remember, Power is bounded between $1 - P(\\text{False Negative})$, or $1-\\beta$. \n",
    "The other component of power is the actual __effect size__ (ratio of the difference in means divided by the standard deviation) that we want to be able __consistently__ label as significant. \n",
    "As quantitative biologists, we must be aware of how all of these components effect one another. \n",
    "Consider the following experiment, and answer the questions in the quiz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(effect_size = 0.1, n=1000):\n",
    "    mu_A = 0\n",
    "    sigma = 2\n",
    "    \n",
    "    mu_B = sigma*effect_size+mu_A\n",
    "    A = [random.gauss(mu_A, sigma) for _ in range(n)]\n",
    "    B = [random.gauss(mu_B, sigma) for _ in range(n)]\n",
    "    return A, B\n",
    "\n",
    "@widgets.interact_manual(effect_size=(0.0,1.0), n=[3,10,30,100])\n",
    "def run_ttest(effect_size, n):\n",
    "    A,B = run_experiment(effect_size)\n",
    "    pvalues=[]\n",
    "    for i in range(0,200):\n",
    "        tstat, pvalue = ttest(np.random.choice(A, size=n), np.random.choice(B, size=n))\n",
    "        pvalues.append(pvalue)\n",
    "    p_arr = np.array(pvalues)\n",
    "    power = 1 - np.count_nonzero((p_arr > 0.05))/p_arr.size\n",
    "    print(f\"Power: {power}\")\n",
    "    sns.histplot(pvalues, stat=\"probability\", kde=\"true\")\n",
    "    plt.title(f\"Histogram of p-values, sample size = {n}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Multiple tests\n",
    "\n",
    "Data source: https://reneshbedre.github.io/assets/posts/anova/twowayanova.txt\n",
    "\n",
    "This data is not real data, so we will not be focusing on interpreting the biological results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df = pd.read_csv(\"https://reneshbedre.github.io/assets/posts/anova/twowayanova.txt\", sep=\"\\t\")\n",
    "basic_df.columns = [\"Genotype\", \"Year1\", \"Year2\", \"Year3\"]\n",
    "subsample_genotypes = [\"A\",\"B\",\"C\",\"D\"]\n",
    "subsample = pd.concat([x for g,x in basic_df.groupby(\"Genotype\") if g in [\"A\",\"B\",\"C\",\"D\"]])\n",
    "subsample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorial _t_-test\n",
    "\n",
    "We have a higher chance of seeing a false positive when we run multiple tests! \n",
    "If you ran the test for 0.0 effect size, the p-value is uniformly distributed between 0 and 1, which is expected.\n",
    "That means with an alpha of 0.05, we would say 5% of our tests are significant even though we have no effect!\n",
    "Remember, alpha is our False Negative rate as well. \n",
    "The most common (and most strict) correction that we can do is divide our original $\\alpha$ by the number of tests that we run, which is called the Bonferroni correction. \n",
    "Remember that decreasing our $\\alpha$, increases our $\\beta$, and therefore decreases our power. If this last sentence doesn't make sense to you, ask!\n",
    "We shall explore that more in the experiment below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(year=\"Year1\"):\n",
    "    pvalues = np.zeros(shape=(4,4))\n",
    "    i=0\n",
    "    for genotype, genotype_df in subsample.groupby(\"Genotype\"):\n",
    "        for j, other_geno in enumerate(subsample_genotypes):\n",
    "            other = subsample[subsample[\"Genotype\"] == other_geno]\n",
    "            tstat, pvalue = ttest(genotype_df[year], other[year])\n",
    "            pvalues[i][j] = pvalue\n",
    "        i += 1\n",
    "        \n",
    "    mask = np.triu(np.ones_like(pvalues, dtype=bool))\n",
    "    sns.heatmap(pvalues, mask=mask, cmap=\"Blues_r\", annot=True, fmt=\"0.4f\", \n",
    "                xticklabels=subsample_genotypes,\n",
    "                yticklabels=subsample_genotypes)\n",
    "    plt.title(f\"p-values for {year}\")\n",
    "    plt.show()\n",
    "    return pvalues\n",
    "\n",
    "array_list = []\n",
    "for year in [\"Year1\", \"Year3\"]:\n",
    "    array_list.append(combinations(year))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3-5: ANOVA\n",
    "\n",
    "ANOVA, discussed on Monday, is one way that we can compare all the means between groups, so that we can reduce it to one test instead of every combination of _t_-test! \n",
    "You will see that the dataset was actually shorted for the purposes of the last exercise, but there are in fact 6 groups rather than 4 (which greatly increases the number of tests).\n",
    "\n",
    "Let's dive into ANOVA, but first we will view the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA\n",
    "Note:\n",
    "- df: the degrees of freedom for each term in the model\n",
    "- sum_sq: the sum of squares for each term in the model\n",
    "- F: the F-statistic for each term in the model\n",
    "- PR(>F): the p-value for each term in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_oneway_anova(df, independent = \"Genotype\", dependent = \"Year1\"):\n",
    "    model = ols(f'{dependent} ~ C({independent})', data=df).fit()\n",
    "    aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "    sns.boxplot(data=df, y=dependent, x=independent)\n",
    "    return aov_table\n",
    "    \n",
    "@widgets.interact(dependent=[\"Year1\", \"Year2\", \"Year3\"])\n",
    "def anova_by_year(dependent):\n",
    "    return perform_oneway_anova(basic_df, independent=\"Genotype\", dependent = dependent)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if there is a second category that we care about, like the year? \n",
    "We can use two-way ANOVA to try to capture this additional layer of complexity. \n",
    "There are a couple different ways of calculating this, but it is possible to account for the __interaction__ of two variables by also using the _covariance_ as one of the variables. \n",
    "We will cover this in more detail in the future! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_twoway_anova(df, interaction=False, ind = [\"Genotype\", \"years\"], dep = \"value\"):\n",
    "    d_melt = pd.melt(df, id_vars=['Genotype'], value_vars=['Year1', 'Year2', 'Year3'])\n",
    "    d_melt.columns = ['Genotype', 'years', 'value']\n",
    "    \n",
    "    if interaction: \n",
    "        model = ols(f'{dep} ~ C({ind[0]}) + C({ind[1]}) + C({ind[0]}):C({ind[1]})', data=d_melt).fit()\n",
    "    else: \n",
    "        model = ols(f'{dep} ~ C({ind[0]}) + C({ind[1]})', data=d_melt).fit()\n",
    "    aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "    return aov_table\n",
    "\n",
    "@widgets.interact(interaction=[False,True])\n",
    "def ineractions_twoway_anova(interaction):\n",
    "    return perform_twoway_anova(basic_df, interaction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: How do we represent data\n",
    "\n",
    "Why does the __structure__ of data matter? \n",
    "There is a lot of math that is important to calculating statistics. \n",
    "There is not a lot we can do with words, so we need to represent them as numbers. \n",
    "\n",
    "There are several different types of variables that contain valuable information: \n",
    "-  Categorical: Variables than can be placed into bins (something like species, or diseases)\n",
    "-  Ordinal: Ordered categorical variables (think stages of a disease)\n",
    "-  Binary (boolean): True/False (Any categorical variable can be written as multiple binary variables)\n",
    "-  Continuous: All real numbers (can be bounded)\n",
    "-  Discrete: Limited selection of distinct numbers \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We skipped a step that was important to the two-way ANOVA. We formatted our data as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatted data\n",
    "\n",
    "Notice that we aren't losing any information by reshaping the data.\n",
    "We are still able to capture the behavior of years, but we also now have more observations to compare Genotype with. \n",
    "This restructuring causes the _p_-values to be lower in the two-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_melt = pd.melt(basic_df, id_vars=['Genotype'], value_vars=['Year1', 'Year2', 'Year3'])\n",
    "d_melt.columns = ['Genotype', 'years', 'value']\n",
    "d_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also commonly represent data as a matrix, which is useful for a lot of mathematical operations that we may want to do, which we will discuss more in the future. \n",
    "Whenever we show you tables, we can generally refer to that as a matrix.\n",
    "However, as we just showed, rows and columns aren't intrinsic components of data. \n",
    "\n",
    "We (and the internet) will generally refer to dependent variables as __responses__ (continuous) or __labels__ (categorical), independent variables as __features__, and individual samples as __observations__. \n",
    "These are generally used as terms to describe models, but can be useful when discussing the structure of data as well.\n",
    "\n",
    "![annotated_data](annotated_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a couple of definitions out of the way, let us look at the structure of some blood test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_lab_data(n=12):\n",
    "    lab_data = pd.read_csv(\"data/hcvdat0.csv\", index_col=0)\n",
    "    lab_data = lab_data[lab_data[\"Category\"] != \"0s=suspect Blood Donor\"]\n",
    "    lab_data = lab_data.dropna(axis=0)\n",
    "    df_list = []\n",
    "    for category, category_df in lab_data.groupby(\"Category\"):\n",
    "        df_list.append(category_df.sample(n, random_state=5))\n",
    "    \n",
    "    return pd.concat(df_list)\n",
    "        \n",
    "\n",
    "lab_data = clean_lab_data()\n",
    "print(lab_data.shape)\n",
    "lab_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- albumin (ALB)\n",
    "\n",
    "- alkaline phosphatase (ALP)\n",
    "\n",
    "- alanine amino-transferase (ALT)\n",
    "\n",
    "- aspartate amino-transferase (AST)\n",
    "\n",
    "- bilirubin (BIL) \n",
    "\n",
    "- choline esterase (CHE)\n",
    "\n",
    "- cholesterol (CHOL)\n",
    "\n",
    "- creatinine (CREA)* \n",
    "\n",
    "- γ-glutamyl-transferase (GGT)\n",
    "\n",
    "- total protein (PROT)*\n",
    "\n",
    "\\* I think, the dataset was not very well annotated.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/HCV+data#\n",
    "\n",
    "We have gone through and cleaned out some of the data that was incomplete, and also reduced the samples to be the same across all groups. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7-8: ANOVA assumptions\n",
    "\n",
    "We have mentioned the idea of a \"normality\" assumption multiple times through this class, and there are statistical tests that help test for normality. \n",
    "However, those tests are a little more complicated, but one option is using QQ-plots or Quantile-Quantile plots to assess how well the data matches with a distribution. \n",
    "It is a plot comparing the probability of the sample occruing in the data, and the probability that the sample occurs in a normal distribution.\n",
    "If it falls on the line, it is safe to treat it as normal. \n",
    "\n",
    "![qqplots](qqplot.png)\n",
    "\n",
    "__Aside__: As a result of the CLT, ANOVA, similarly to t-tests, is generally robust to departures from normality and differences in variance, but at large sample sizes. If you have a small sample size, the ANOVA is no longer robust to departures from the assumptions made when designing the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@widgets.interact(feature = [\"ALB\", \"ALP\", \"ALT\", \"AST\", \"BIL\", \"CHE\", \"CHOL\", \"CREA\", \"GGT\", \"PROT\"])\n",
    "def show_hist_gg_plots(feature = \"ALB\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,8))\n",
    "    sns.histplot(data=lab_data, x=feature, hue=\"Category\", stat=\"probability\", kde=True, ax=ax1)\n",
    "    qqplot(lab_data[feature].dropna(), norm, fit=True, line=\"45\", ax=ax2)\n",
    "    plt.show()\n",
    "    return perform_oneway_anova(lab_data, independent = \"Category\", dependent = feature)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Tying in to linear models\n",
    "\n",
    "There is another common way of thinking about ANOVA: a linear model where the means ($\\bar{X}_i = \\hat{\\beta}_i$ of a group are the best prediction of any individual group value.\n",
    "Remember that any categorical variable can be written as a series of binary variables. \n",
    "This transformation is called \"One-hot encoding\". \n",
    "Let's say that we have 3 groups, we can rewrite this as 3 binary features: $x_a$, $x_b$, $x_c$ that indicate what group a observation belongs to. \n",
    "If we rewrite categorical variables in this way, we can use a mathematical formula to capture the behavior of the groups to predict some response $y$:\n",
    "\n",
    "$$ y = \\hat{\\beta}_a x_a + \\hat{\\beta}_b x_b + \\hat{\\beta}_c x_c $$\n",
    "\n",
    "This result is the solution to the __least squares__ problem, which is also how we will solve the linear regression problem.\n",
    "This model (using __error__ or the __residuals__) is then compared to comparing to simply using the average of all the groups to predict $y$. \n",
    "This notation will start to look much more familiar starting next week. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
